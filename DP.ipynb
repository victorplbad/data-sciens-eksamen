{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Fake News Project\n",
    "# Part 1: Data Processing\n",
    "### Task 1: Retrieve sample of FakeNewsCorups\n",
    "https://raw.githubusercontent.com/several27/FakeNewsCorpus/master/news_sample.csv\n",
    "\n",
    "Check requirements for version control for our libraries used in this project.\n",
    "- MatPlotLib \n",
    "- scikit-learn\n",
    "- pandas\n",
    "- NLTK\n",
    "- pytorch\n",
    "- numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\alfem\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\alfem\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "from nltk.stem.porter import *\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "english_stopwords = stopwords.words('english')\n",
    "stopwords = stopwords.words('english')\n",
    "\n",
    "def full_clean(text: str, stopwords=english_stopwords):\n",
    "    text = text.lower()\n",
    "\n",
    "    text = re.sub(r'\\n', ' ', text) # Remove newlines\n",
    "    text = re.sub(r' +', ' ', text) # Remove multiple spaces\n",
    "\n",
    "    text = re.sub(r'([a-zA-Z]+) (\\d+)[, ]? (\\d{4})', '<DATE>', text) # Date substitution\n",
    "    text = re.sub(r'([.a-zA-Z0-9]+)@([-a-zA-Z0-9]+).([a-zA-Z]+)', '<EMAIL>', text) # E-Mail substitution\n",
    "    text = re.sub(r'(https?:\\/\\/)?(www.)?([-.a-zA-Z0-9]+)[.](co.uk|com|org|net)\\/?([\\%\\-\\.\\?\\_=a-zA-Z0-9\\/]+)?', '<URL>', text) # URL substitution\n",
    "    text = re.sub(r'[0-9]+', '<NUM>', text) # Number substitution\n",
    "\n",
    "    stemmer = PorterStemmer()                                   # Porter Stemmer from nltk\n",
    "    tokens = nltk.word_tokenize(text)                           # Tokenizing the text\n",
    "    tokens = [word for word in tokens if word.isalpha()]        # Removing punctuation\n",
    "    tokens = [word for word in tokens if word not in stopwords] # Removing Stopwords\n",
    "    tokens = [stemmer.stem(word) for word in tokens]            # Stemming all the words\n",
    "    return ' '.join(tokens) # Returning a string consisting of each word in the list\n",
    "\n",
    "def is_credible(article_type):\n",
    "    if article_type in ['fake', 'satire', 'conspiracy', 'bias', 'hate', 'junksci']:\n",
    "        return int(0)\n",
    "    \n",
    "    elif article_type in ['clickbait', 'political', 'reliable']:\n",
    "        return int(1)\n",
    "    \n",
    "    else:\n",
    "        return int(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Apply data pre-processing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              content\n",
      "0   plu one articl googl plu thank ali alfoneh ass...\n",
      "1   cost best senat bank committe jp morgan buy nu...\n",
      "2   man awoken num coma commit suicid learn donald...\n",
      "3   julia geist ask draw pictur comput scientist l...\n",
      "4   num compil studi vaccin danger activist post n...\n",
      "5   spend major wake hour stare contentedli comput...\n",
      "6   disclaim gener inform law topic noth diari con...\n",
      "7   new report identifi num epicent worldwid chang...\n",
      "9   dear reader excit announc voic russia chang na...\n",
      "11  say republican want privat medicar say go tri ...\n"
     ]
    }
   ],
   "source": [
    "# Retrieve sample of FakeNewsCorpus\n",
    "df = pd.read_csv(\"src/995,000_rows.csv\", usecols = [\"type\", \"content\"]) # **WARNING big file, use local directory**\n",
    "\n",
    "# Remove na instances\n",
    "df = df.dropna()\n",
    "\n",
    "# Remove duplicates\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Omit unnessecary types\n",
    "omit_types = ['unreliable', 'unknown', 'rumor', \n",
    "              '2018-02-10 13:43:39.521661']\n",
    "\n",
    "for omit_type in omit_types:\n",
    "    df = df[df.type != omit_type]\n",
    "\n",
    "# Apply full_clean on dataset\n",
    "df[\"content\"] = df[\"content\"].apply(full_clean)\n",
    "\n",
    "# Apply is_credible on dataset\n",
    "df['type'] = df['type'].apply(is_credible)\n",
    "\n",
    "# Save Cleaned Data\n",
    "df.to_csv(\"src/clean_995000_news.csv\", index=False)\n",
    "\n",
    "# Display Sample Results\n",
    "print(df[[\"content\"]].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Exploration of proccesed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    type                                            content\n",
      "0      1  plu one articl googl plu thank ali alfoneh ass...\n",
      "1      0  cost best senat bank committe jp morgan buy nu...\n",
      "2      0  man awoken num coma commit suicid learn donald...\n",
      "3      1  julia geist ask draw pictur comput scientist l...\n",
      "4      0  num compil studi vaccin danger activist post n...\n",
      "..   ...                                                ...\n",
      "95     0  jump navig link page namespac main talk user u...\n",
      "96     1  editor miep gie num last hid ann frank famili ...\n",
      "97     0  potenti num gop presidenti candid ben carson s...\n",
      "98     1  back forth fight trump administr court constit...\n",
      "99     1  idea smithsonian latino museum born num task f...\n",
      "\n",
      "[100 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Read \"cleaned_995000_news.csv\"\n",
    "new_sample = pd.read_csv(\"src/clean_995000_news.csv\") # **WARNING big file, use local directory**\n",
    "print(new_sample.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[292426, 378769]\n",
      "Fake news: 292426 Reliable news: 378769\n"
     ]
    }
   ],
   "source": [
    "count_val = list(new_sample[\"type\"].values)\n",
    "\n",
    "# Count instances of fake or reliabe news\n",
    "def fake_credible(types: list):\n",
    "    labels = [0, 0]\n",
    "    \n",
    "    for type in types:\n",
    "        if type == 0:\n",
    "            labels[0] += 1\n",
    "\n",
    "        else:\n",
    "            labels[1] += 1\n",
    "\n",
    "    return labels\n",
    "\n",
    "print(fake_credible(new_sample['type']))\n",
    "\n",
    "print(\"Fake news:\", fake_credible(count_val)[0], \"Reliable news:\", fake_credible(count_val)[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vocab: frequency of words in cleaned dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = []\n",
    "\n",
    "for content in new_sample['content']:\n",
    "    try:\n",
    "        vocab.extend(nltk.word_tokenize(content))\n",
    "    except:\n",
    "        continue\n",
    "vocab = [word for word in vocab if word.isalpha()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(vocab):\n",
    "    words = {}\n",
    "\n",
    "    for word in vocab:\n",
    "        if word in words:\n",
    "            words[word] += 1\n",
    "        else:\n",
    "            words[word] = 1\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort vocab from most frequent to least frequent\n",
    "sorted_vocab = {k: v for k, v in sorted(count_words(vocab).items(), key = lambda item: item[1], reverse=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New dataframe for the 10000 most frequent words\n",
    "frequent_words_10k = pd.DataFrame({'word': list(sorted_vocab)[:10000]})\n",
    "# Exporting dataframe to new csv filde\n",
    "frequent_words_10k.to_csv(\"src/frequent_words_10k.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num': 7547782,\n",
       " 'said': 1196118,\n",
       " 'one': 877892,\n",
       " 'new': 823229,\n",
       " 'time': 790898,\n",
       " 'would': 787511,\n",
       " 'state': 713996,\n",
       " 'year': 711658,\n",
       " 'peopl': 711083,\n",
       " 'like': 669445,\n",
       " 'also': 538100,\n",
       " 'say': 485861,\n",
       " 'make': 477376,\n",
       " 'use': 473712,\n",
       " 'us': 460296,\n",
       " 'get': 459023,\n",
       " 'go': 445635,\n",
       " 'even': 438001,\n",
       " 'work': 423670,\n",
       " 'govern': 412108,\n",
       " 'american': 407231,\n",
       " 'presid': 407040,\n",
       " 'two': 403937,\n",
       " 'report': 401403,\n",
       " 'could': 399181,\n",
       " 'first': 396646,\n",
       " 'mani': 394487,\n",
       " 'continu': 394227,\n",
       " 'stori': 389893,\n",
       " 'read': 385399,\n",
       " 'nation': 366554,\n",
       " 'right': 362940,\n",
       " 'day': 358987,\n",
       " 'take': 350470,\n",
       " 'trump': 349785,\n",
       " 'world': 348271,\n",
       " 'last': 344738,\n",
       " 'way': 334669,\n",
       " 'think': 334372,\n",
       " 'want': 330366,\n",
       " 'call': 326812,\n",
       " 'know': 326412,\n",
       " 'url': 322213,\n",
       " 'news': 321172,\n",
       " 'may': 321051,\n",
       " 'york': 321020,\n",
       " 'come': 313354,\n",
       " 'need': 308642,\n",
       " 'countri': 308067,\n",
       " 'includ': 302200,\n",
       " 'see': 297020,\n",
       " 'obama': 289422,\n",
       " 'back': 283989,\n",
       " 'much': 280486,\n",
       " 'unit': 276565,\n",
       " 'well': 276060,\n",
       " 'show': 273224,\n",
       " 'tri': 272257,\n",
       " 'date': 270401,\n",
       " 'polit': 269111,\n",
       " 'support': 268270,\n",
       " 'thing': 264348,\n",
       " 'pleas': 264196,\n",
       " 'hous': 262534,\n",
       " 'look': 261861,\n",
       " 'group': 258533,\n",
       " 'live': 257932,\n",
       " 'compani': 256815,\n",
       " 'main': 254545,\n",
       " 'help': 248963,\n",
       " 'made': 247585,\n",
       " 'law': 247542,\n",
       " 'sign': 243414,\n",
       " 'public': 241987,\n",
       " 'million': 241690,\n",
       " 'war': 240823,\n",
       " 'good': 237697,\n",
       " 'week': 233000,\n",
       " 'sinc': 230387,\n",
       " 'still': 229769,\n",
       " 'percent': 229385,\n",
       " 'point': 229196,\n",
       " 'republican': 228938,\n",
       " 'democrat': 227900,\n",
       " 'part': 226101,\n",
       " 'chang': 224575,\n",
       " 'power': 223822,\n",
       " 'servic': 221826,\n",
       " 'citi': 221501,\n",
       " 'offic': 221298,\n",
       " 'plan': 215828,\n",
       " 'gener': 215397,\n",
       " 'anoth': 211886,\n",
       " 'end': 210441,\n",
       " 'newslett': 210330,\n",
       " 'forc': 209467,\n",
       " 'market': 203684,\n",
       " 'must': 203246,\n",
       " 'issu': 201368,\n",
       " 'vote': 199659,\n",
       " 'offici': 199580,\n",
       " 'fact': 199057,\n",
       " 'famili': 198455,\n",
       " 'start': 197976,\n",
       " 'product': 197883,\n",
       " 'follow': 197068,\n",
       " 'case': 195861,\n",
       " 'parti': 195857,\n",
       " 'life': 195327,\n",
       " 'school': 195193,\n",
       " 'place': 194972,\n",
       " 'believ': 193979,\n",
       " 'accord': 193700,\n",
       " 'elect': 193096,\n",
       " 'america': 191977,\n",
       " 'person': 190959,\n",
       " 'offer': 188950,\n",
       " 'recent': 188530,\n",
       " 'ask': 187989,\n",
       " 'home': 187339,\n",
       " 'everi': 187180,\n",
       " 'view': 186239,\n",
       " 'system': 186111,\n",
       " 'white': 185681,\n",
       " 'three': 184617,\n",
       " 'secur': 184506,\n",
       " 'today': 184211,\n",
       " 'receiv': 183828,\n",
       " 'talk': 183286,\n",
       " 'month': 182157,\n",
       " 'play': 179973,\n",
       " 'around': 179917,\n",
       " 'advertis': 178793,\n",
       " 'told': 178444,\n",
       " 'long': 178046,\n",
       " 'never': 177638,\n",
       " 'feder': 176408,\n",
       " 'attack': 176343,\n",
       " 'money': 175830,\n",
       " 'give': 175337,\n",
       " 'next': 175267,\n",
       " 'put': 174845,\n",
       " 'в': 173751,\n",
       " 'member': 173706,\n",
       " 'number': 173401,\n",
       " 'health': 173178,\n",
       " 'run': 172755,\n",
       " 'find': 171918,\n",
       " 'later': 171860,\n",
       " 'found': 171661,\n",
       " 'polic': 170640,\n",
       " 'busi': 170595,\n",
       " 'mean': 169575,\n",
       " 'becom': 168866,\n",
       " 'campaign': 168008,\n",
       " 'realli': 167859,\n",
       " 'provid': 167531,\n",
       " 'question': 166555,\n",
       " 'polici': 166300,\n",
       " 'senat': 166279,\n",
       " 'inform': 164304,\n",
       " 'post': 163729,\n",
       " 'seem': 163353,\n",
       " 'media': 163200,\n",
       " 'without': 162479,\n",
       " 'major': 160753,\n",
       " 'man': 160720,\n",
       " 'differ': 160415,\n",
       " 'human': 159650,\n",
       " 'children': 159154,\n",
       " 'commun': 158644,\n",
       " 'interest': 156417,\n",
       " 'bill': 156284,\n",
       " 'open': 155565,\n",
       " 'move': 155465,\n",
       " 'sourc': 155432,\n",
       " 'email': 154408,\n",
       " 'might': 154086,\n",
       " 'happen': 154074,\n",
       " 'organ': 153934,\n",
       " 'bank': 153789,\n",
       " 'keep': 153771,\n",
       " 'women': 153244,\n",
       " 'subscrib': 153050,\n",
       " 'court': 152730,\n",
       " 'turn': 152573,\n",
       " 'program': 152507,\n",
       " 'tax': 152425,\n",
       " 'name': 152057,\n",
       " 'author': 152018,\n",
       " 'univers': 151445,\n",
       " 'share': 150264,\n",
       " 'militari': 150136,\n",
       " 'creat': 149892,\n",
       " 'someth': 149713,\n",
       " 'great': 149145,\n",
       " 'job': 149017,\n",
       " 'ad': 148969,\n",
       " 'problem': 148799,\n",
       " 'order': 148743,\n",
       " 'street': 148128,\n",
       " 'care': 146688,\n",
       " 'special': 144993,\n",
       " 'former': 144955,\n",
       " 'clinton': 144893,\n",
       " 'littl': 144316,\n",
       " 'kill': 144267,\n",
       " 'control': 143687,\n",
       " 'administr': 142936,\n",
       " 'game': 142816,\n",
       " 'book': 141404,\n",
       " 'claim': 141360,\n",
       " 'act': 140957,\n",
       " 'allow': 140916,\n",
       " 'set': 140464,\n",
       " 'reason': 140241,\n",
       " 'result': 140188,\n",
       " 'increas': 139932,\n",
       " 'left': 139286,\n",
       " 'sever': 139177,\n",
       " 'articl': 138894,\n",
       " 'let': 138801,\n",
       " 'agre': 138220,\n",
       " 'import': 138078,\n",
       " 'high': 137662,\n",
       " 'intern': 137251,\n",
       " 'washington': 136889,\n",
       " 'howev': 136085,\n",
       " 'econom': 135932,\n",
       " 'big': 135763,\n",
       " 'lead': 135549,\n",
       " 'develop': 134829,\n",
       " 'rate': 134461,\n",
       " 'appear': 134235,\n",
       " 'free': 133633,\n",
       " 'research': 133409,\n",
       " 'best': 133222,\n",
       " 'black': 133078,\n",
       " 'far': 132368,\n",
       " 'team': 131781,\n",
       " 'thank': 131126,\n",
       " 'actual': 130940,\n",
       " 'lot': 130830,\n",
       " 'oper': 130817,\n",
       " 'leader': 130470,\n",
       " 'possibl': 130413,\n",
       " 'video': 130266,\n",
       " 'feel': 130251,\n",
       " 'center': 130123,\n",
       " 'photo': 130004,\n",
       " 'base': 129770,\n",
       " 'face': 129691,\n",
       " 'second': 129174,\n",
       " 'real': 129166,\n",
       " 'address': 128367,\n",
       " 'close': 128093,\n",
       " 'love': 127950,\n",
       " 'better': 127390,\n",
       " 'current': 127198,\n",
       " 'depart': 127189,\n",
       " 'respons': 127036,\n",
       " 'less': 126861,\n",
       " 'rule': 126749,\n",
       " 'yet': 126479,\n",
       " 'alreadi': 126463,\n",
       " 'though': 126435,\n",
       " 'и': 126203,\n",
       " 'studi': 125960,\n",
       " 'effect': 125858,\n",
       " 'pay': 125583,\n",
       " 'note': 125003,\n",
       " 'build': 124983,\n",
       " 'protect': 124983,\n",
       " 'th': 124741,\n",
       " 'least': 124143,\n",
       " 'price': 123569,\n",
       " 'word': 123433,\n",
       " 'john': 123027,\n",
       " 'tell': 122968,\n",
       " 'got': 122890,\n",
       " 'russia': 122500,\n",
       " 'expect': 122448,\n",
       " 'deal': 121701,\n",
       " 'caus': 121505,\n",
       " 'social': 120811,\n",
       " 'among': 120638,\n",
       " 'meet': 120096,\n",
       " 'food': 120057,\n",
       " 'fund': 119820,\n",
       " 'hope': 119555,\n",
       " 'hand': 118685,\n",
       " 'de': 118125,\n",
       " 'area': 117833,\n",
       " 'investig': 116856,\n",
       " 'posit': 115857,\n",
       " 'student': 115718,\n",
       " 'stop': 115621,\n",
       " 'histori': 114845,\n",
       " 'record': 114199,\n",
       " 'away': 114055,\n",
       " 'head': 113578,\n",
       " 'manag': 113274,\n",
       " 'past': 113007,\n",
       " 'larg': 112888,\n",
       " 'ago': 112837,\n",
       " 'action': 112637,\n",
       " 'enough': 112391,\n",
       " 'whether': 112234,\n",
       " 'billion': 112213,\n",
       " 'line': 112068,\n",
       " 'global': 111988,\n",
       " 'other': 111908,\n",
       " 'consid': 111905,\n",
       " 'natur': 111737,\n",
       " 'remain': 111420,\n",
       " 'updat': 111024,\n",
       " 'requir': 110555,\n",
       " 'level': 110541,\n",
       " 'occur': 110185,\n",
       " 'cost': 109947,\n",
       " 'top': 109946,\n",
       " 'pass': 109908,\n",
       " 'came': 109512,\n",
       " 'alway': 109504,\n",
       " 'cours': 108938,\n",
       " 'industri': 108730,\n",
       " 'death': 108608,\n",
       " 'water': 108595,\n",
       " 'releas': 108127,\n",
       " 'four': 107860,\n",
       " 'men': 107598,\n",
       " 'bush': 106397,\n",
       " 'took': 106344,\n",
       " 'thought': 105941,\n",
       " 'event': 105841,\n",
       " 'local': 105807,\n",
       " 'friend': 105446,\n",
       " 'financi': 105332,\n",
       " 'ever': 105222,\n",
       " 'final': 104869,\n",
       " 'russian': 104811,\n",
       " 'congress': 104760,\n",
       " 'fight': 104681,\n",
       " 'execut': 103979,\n",
       " 'critic': 103585,\n",
       " 'idea': 103530,\n",
       " 'cut': 103313,\n",
       " 'win': 102551,\n",
       " 'side': 102517,\n",
       " 'click': 102429,\n",
       " 'matter': 102264,\n",
       " 'given': 102149,\n",
       " 'comment': 101629,\n",
       " 'foreign': 101436,\n",
       " 'night': 101356,\n",
       " 'noth': 100894,\n",
       " 'agenc': 100697,\n",
       " 'often': 100474,\n",
       " 'select': 100404,\n",
       " 'hold': 100296,\n",
       " 'watch': 100214,\n",
       " 'concern': 99945,\n",
       " 'director': 99845,\n",
       " 'effort': 99723,\n",
       " 'oil': 99721,\n",
       " 'candid': 99696,\n",
       " 'decis': 99628,\n",
       " 'sure': 99435,\n",
       " 'north': 99082,\n",
       " 'hour': 98989,\n",
       " 'repres': 98860,\n",
       " 'leav': 98665,\n",
       " 'list': 98664,\n",
       " 'charg': 98515,\n",
       " 'kind': 98331,\n",
       " 'rec': 97646,\n",
       " 'small': 97175,\n",
       " 'statement': 96979,\n",
       " 'process': 96873,\n",
       " 'energi': 96858,\n",
       " 'china': 96807,\n",
       " 'press': 96540,\n",
       " 'conserv': 96247,\n",
       " 'project': 95984,\n",
       " 'futur': 95916,\n",
       " 'involv': 95738,\n",
       " 'young': 95659,\n",
       " 'understand': 95651,\n",
       " 'trade': 95599,\n",
       " 'relat': 95411,\n",
       " 'old': 94979,\n",
       " 'known': 94867,\n",
       " 'activ': 94741,\n",
       " 'return': 94684,\n",
       " 'begin': 94537,\n",
       " 'box': 94496,\n",
       " 'serv': 94495,\n",
       " 'economi': 93922,\n",
       " 'went': 93709,\n",
       " 'associ': 93660,\n",
       " 'write': 93438,\n",
       " 'educ': 93241,\n",
       " 'rais': 93092,\n",
       " 'immigr': 92824,\n",
       " 'account': 92725,\n",
       " 'clear': 92533,\n",
       " 'site': 92494,\n",
       " 'earli': 92417,\n",
       " 'bring': 92351,\n",
       " 'form': 92295,\n",
       " 'term': 92234,\n",
       " 'stand': 91250,\n",
       " 'done': 91249,\n",
       " 'fire': 91232,\n",
       " 'within': 91123,\n",
       " 'south': 91080,\n",
       " 'suggest': 91075,\n",
       " 'complet': 90993,\n",
       " 'spend': 90832,\n",
       " 'seen': 90826,\n",
       " 'god': 90826,\n",
       " 'defens': 90154,\n",
       " 'learn': 90148,\n",
       " 'almost': 90106,\n",
       " 'die': 89862,\n",
       " 'exampl': 89844,\n",
       " 'abl': 89795,\n",
       " 'iraq': 89294,\n",
       " 'announc': 89139,\n",
       " 'full': 89089,\n",
       " 'privat': 88943,\n",
       " 'legal': 88901,\n",
       " 'five': 88558,\n",
       " 'west': 88267,\n",
       " 'union': 88227,\n",
       " 'discuss': 87688,\n",
       " 'drug': 87263,\n",
       " 'present': 86951,\n",
       " 'origin': 85974,\n",
       " 'publish': 85690,\n",
       " 'across': 85484,\n",
       " 'experi': 85402,\n",
       " 'instead': 85270,\n",
       " 'evid': 85136,\n",
       " 'friday': 85103,\n",
       " 'interview': 85044,\n",
       " 'produc': 84837,\n",
       " 'along': 84218,\n",
       " 'race': 84176,\n",
       " 'error': 84089,\n",
       " 'design': 83964,\n",
       " 'bodi': 83831,\n",
       " 'israel': 83628,\n",
       " 'voter': 83609,\n",
       " 'direct': 83358,\n",
       " 'islam': 83303,\n",
       " 'daili': 83228,\n",
       " 'individu': 82848,\n",
       " 'age': 82835,\n",
       " 'rather': 82771,\n",
       " 'hard': 82614,\n",
       " 'perform': 82507,\n",
       " 'anyth': 82058,\n",
       " 'muslim': 81958,\n",
       " 'donald': 81879,\n",
       " 'corpor': 81818,\n",
       " 'season': 81810,\n",
       " 'institut': 81696,\n",
       " 'justic': 81307,\n",
       " 'protest': 81263,\n",
       " 'speak': 81052,\n",
       " 'buy': 80866,\n",
       " 'explain': 80825,\n",
       " 'worker': 80513,\n",
       " 'на': 80238,\n",
       " 'valu': 79923,\n",
       " 'christian': 79731,\n",
       " 'dollar': 79661,\n",
       " 'fail': 79607,\n",
       " 'test': 79478,\n",
       " 'la': 79404,\n",
       " 'region': 79309,\n",
       " 'air': 79179,\n",
       " 'taken': 79138,\n",
       " 'someon': 79018,\n",
       " 'constitut': 78873,\n",
       " 'chief': 78659,\n",
       " 'church': 78611,\n",
       " 'wrote': 78429,\n",
       " 'occasion': 78313,\n",
       " 'sunday': 77932,\n",
       " 'mind': 77688,\n",
       " 'invest': 77623,\n",
       " 'committe': 77504,\n",
       " 'medic': 77329,\n",
       " 'page': 77211,\n",
       " 'reach': 77135,\n",
       " 'success': 77124,\n",
       " 'decid': 77051,\n",
       " 'addit': 76926,\n",
       " 'east': 76878,\n",
       " 'add': 76772,\n",
       " 'tuesday': 76632,\n",
       " 'gun': 76616,\n",
       " 'benefit': 76600,\n",
       " 'art': 76558,\n",
       " 'total': 76414,\n",
       " 'hear': 76289,\n",
       " 'robot': 76141,\n",
       " 'visit': 76079,\n",
       " 'cover': 76015,\n",
       " 'stock': 75965,\n",
       " 'risk': 75879,\n",
       " 'attempt': 75877,\n",
       " 'behind': 75670,\n",
       " 'late': 75455,\n",
       " 'hit': 75381,\n",
       " 'true': 75351,\n",
       " 'entir': 75302,\n",
       " 'bad': 75302,\n",
       " 'iran': 75296,\n",
       " 'grow': 75173,\n",
       " 'data': 75008,\n",
       " 'demand': 74811,\n",
       " 'societi': 74734,\n",
       " 'carri': 74724,\n",
       " 'judg': 74682,\n",
       " 'fall': 74659,\n",
       " 'liber': 74418,\n",
       " 'terrorist': 74216,\n",
       " 'toward': 74108,\n",
       " 'verifi': 74088,\n",
       " 'monday': 74083,\n",
       " 'citizen': 74023,\n",
       " 'imag': 73984,\n",
       " 'everyon': 73928,\n",
       " 'lost': 73823,\n",
       " 'nuclear': 73729,\n",
       " 'probabl': 73669,\n",
       " 'began': 73495,\n",
       " 'anyon': 73427,\n",
       " 'colleg': 73398,\n",
       " 'land': 73151,\n",
       " 'car': 73041,\n",
       " 'civil': 73014,\n",
       " 'cultur': 72973,\n",
       " 'hillari': 72936,\n",
       " 'practic': 72818,\n",
       " 'step': 72750,\n",
       " 'exist': 72688,\n",
       " 'togeth': 72523,\n",
       " 'father': 72447,\n",
       " 'crime': 72442,\n",
       " 'technolog': 72438,\n",
       " 'arm': 72438,\n",
       " 'link': 72330,\n",
       " 'music': 72319,\n",
       " 'limit': 72184,\n",
       " 'parent': 72115,\n",
       " 'board': 71921,\n",
       " 'whose': 71882,\n",
       " 'syria': 71771,\n",
       " 'film': 71704,\n",
       " 'light': 71640,\n",
       " 'train': 71394,\n",
       " 'intellig': 71309,\n",
       " 'woman': 71297,\n",
       " 'save': 70924,\n",
       " 'weapon': 70710,\n",
       " 'district': 70466,\n",
       " 'simpli': 70402,\n",
       " 'propos': 70258,\n",
       " 'minist': 70173,\n",
       " 'challeng': 70122,\n",
       " 'per': 70092,\n",
       " 'half': 70055,\n",
       " 'european': 69944,\n",
       " 'everyth': 69815,\n",
       " 'mother': 69758,\n",
       " 'especi': 69628,\n",
       " 'wall': 69542,\n",
       " 'break': 69445,\n",
       " 'thursday': 69362,\n",
       " 'invalid': 69251,\n",
       " 'held': 69228,\n",
       " 'march': 69171,\n",
       " 'truth': 69125,\n",
       " 'potenti': 69113,\n",
       " 'threat': 68975,\n",
       " 'describ': 68700,\n",
       " 'answer': 68535,\n",
       " 'popul': 68517,\n",
       " 'role': 68442,\n",
       " 'detail': 68316,\n",
       " 'middl': 68314,\n",
       " 'decad': 68299,\n",
       " 'outsid': 68245,\n",
       " 'central': 67976,\n",
       " 'freedom': 67976,\n",
       " 'nearli': 67825,\n",
       " 'either': 67736,\n",
       " 'wednesday': 67600,\n",
       " 'target': 67492,\n",
       " 'counti': 67452,\n",
       " 'join': 67422,\n",
       " 'movement': 67276,\n",
       " 'rise': 67102,\n",
       " 'despit': 66963,\n",
       " 'sale': 66925,\n",
       " 'david': 66872,\n",
       " 'sens': 66598,\n",
       " 'fear': 66334,\n",
       " 'document': 66217,\n",
       " 'lie': 66176,\n",
       " 'capit': 66111,\n",
       " 'presidenti': 65986,\n",
       " 'room': 65879,\n",
       " 'poll': 65692,\n",
       " 'class': 65682,\n",
       " 'park': 65616,\n",
       " 'six': 65499,\n",
       " 'figur': 65442,\n",
       " 'europ': 65272,\n",
       " 'file': 65266,\n",
       " 'player': 65190,\n",
       " 'accept': 65176,\n",
       " 'reader': 65164,\n",
       " 'whole': 65151,\n",
       " 'legisl': 64935,\n",
       " 'establish': 64776,\n",
       " 'minut': 64751,\n",
       " 'although': 64690,\n",
       " 'messag': 64544,\n",
       " 'third': 64466,\n",
       " 'collect': 64339,\n",
       " 'thousand': 64334,\n",
       " 'situat': 64326,\n",
       " 'guy': 64210,\n",
       " 'near': 64194,\n",
       " 'peac': 64087,\n",
       " 'avail': 63996,\n",
       " 'perhap': 63973,\n",
       " 'measur': 63931,\n",
       " 'earlier': 63758,\n",
       " 'facebook': 63597,\n",
       " 'becam': 63540,\n",
       " 'refer': 63457,\n",
       " 'debt': 63407,\n",
       " 'son': 63252,\n",
       " 'mark': 63242,\n",
       " 'terror': 63051,\n",
       " 'california': 63005,\n",
       " 'speech': 62941,\n",
       " 'child': 62837,\n",
       " 'commit': 62779,\n",
       " 'paul': 62498,\n",
       " 'twitter': 62374,\n",
       " 'seri': 62341,\n",
       " 'progress': 62314,\n",
       " 'prevent': 62254,\n",
       " 'shot': 62227,\n",
       " 'illeg': 62188,\n",
       " 'stay': 62125,\n",
       " 'warn': 61969,\n",
       " 'debat': 61923,\n",
       " 'push': 61808,\n",
       " 'led': 61763,\n",
       " 'network': 61661,\n",
       " 'review': 61651,\n",
       " 'initi': 61649,\n",
       " 'не': 61609,\n",
       " 'seek': 61433,\n",
       " 'space': 61299,\n",
       " 'field': 61297,\n",
       " 'secretari': 61268,\n",
       " 'common': 61267,\n",
       " 'emerg': 61257,\n",
       " 'saturday': 61188,\n",
       " 'quit': 61145,\n",
       " 'higher': 61013,\n",
       " 'insur': 60990,\n",
       " 'due': 60978,\n",
       " 'wrong': 60895,\n",
       " 'independ': 60852,\n",
       " 'ground': 60576,\n",
       " 'armi': 60321,\n",
       " 'strong': 60237,\n",
       " 'moment': 60146,\n",
       " 'growth': 60002,\n",
       " 'heart': 59974,\n",
       " 'amount': 59956,\n",
       " 'danger': 59925,\n",
       " 'standard': 59735,\n",
       " 'credit': 59540,\n",
       " 'lose': 59306,\n",
       " 'crimin': 59276,\n",
       " 'star': 59127,\n",
       " 'short': 59071,\n",
       " 'rememb': 59011,\n",
       " 'sell': 58932,\n",
       " 'что': 58796,\n",
       " 'reduc': 58712,\n",
       " 'search': 58660,\n",
       " 'walk': 58564,\n",
       " 'express': 58501,\n",
       " 'singl': 58340,\n",
       " 'crisi': 58335,\n",
       " 'drive': 58332,\n",
       " 'access': 58290,\n",
       " 'travel': 58105,\n",
       " 'insid': 57953,\n",
       " 'georg': 57940,\n",
       " 'morn': 57748,\n",
       " 'els': 57738,\n",
       " 'scienc': 57717,\n",
       " 'gold': 57711,\n",
       " 'opportun': 57694,\n",
       " 'front': 57559,\n",
       " 'similar': 57536,\n",
       " 'michael': 57530,\n",
       " 'defend': 57497,\n",
       " 'key': 57471,\n",
       " 'properti': 57444,\n",
       " 'check': 57369,\n",
       " 'reform': 57244,\n",
       " 'border': 57217,\n",
       " 'consum': 57075,\n",
       " 'accus': 57067,\n",
       " 'miss': 57059,\n",
       " 'connect': 57006,\n",
       " 'condit': 56981,\n",
       " 'kid': 56963,\n",
       " 'goal': 56957,\n",
       " 'sound': 56832,\n",
       " 'prepar': 56744,\n",
       " 'remov': 56562,\n",
       " 'longer': 56494,\n",
       " 'rest': 56488,\n",
       " 'arrest': 56443,\n",
       " 'letter': 56427,\n",
       " 'contribut': 56234,\n",
       " 'aid': 56077,\n",
       " 'prison': 56033,\n",
       " 'saw': 55792,\n",
       " 'ye': 55699,\n",
       " 'opposit': 55685,\n",
       " 'averag': 55556,\n",
       " 'promis': 55542,\n",
       " 'period': 55437,\n",
       " 'respect': 55420,\n",
       " 'soon': 55352,\n",
       " 'resid': 55333,\n",
       " 'budget': 55166,\n",
       " 'subject': 55165,\n",
       " 'governor': 55096,\n",
       " 'store': 55050,\n",
       " 'refus': 54833,\n",
       " 'loss': 54719,\n",
       " 'lower': 54475,\n",
       " 'town': 54434,\n",
       " 'confer': 54228,\n",
       " 'violenc': 54228,\n",
       " 'gave': 53956,\n",
       " 'regul': 53951,\n",
       " 'victim': 53915,\n",
       " 'robert': 53886,\n",
       " 'earth': 53884,\n",
       " 'wait': 53869,\n",
       " 'senior': 53763,\n",
       " 'drop': 53700,\n",
       " 'improv': 53663,\n",
       " 'coupl': 53652,\n",
       " 'eye': 53649,\n",
       " 'wife': 53606,\n",
       " 'hospit': 53567,\n",
       " 'send': 53529,\n",
       " 'argu': 53509,\n",
       " 'wonder': 53499,\n",
       " 'chanc': 53345,\n",
       " 'featur': 53328,\n",
       " 'reveal': 53327,\n",
       " 'religi': 53256,\n",
       " 'choic': 53179,\n",
       " 'climat': 53167,\n",
       " 'employe': 53104,\n",
       " 'texa': 53065,\n",
       " 'secret': 52939,\n",
       " 'realiti': 52915,\n",
       " 'upon': 52791,\n",
       " 'specif': 52688,\n",
       " 'certain': 52667,\n",
       " 'low': 52661,\n",
       " 'mass': 52460,\n",
       " 'websit': 52396,\n",
       " 'promot': 52330,\n",
       " 'piec': 52284,\n",
       " 'girl': 52177,\n",
       " 'plant': 52125,\n",
       " 'assist': 52035,\n",
       " 'western': 51943,\n",
       " 'red': 51875,\n",
       " 'respond': 51872,\n",
       " 'type': 51848,\n",
       " 'pictur': 51802,\n",
       " 'gain': 51596,\n",
       " 'sexual': 51563,\n",
       " 'mayb': 51540,\n",
       " 'incom': 51483,\n",
       " 'murder': 51415,\n",
       " 'council': 51373,\n",
       " 'attorney': 51303,\n",
       " 'approach': 51292,\n",
       " 'immedi': 51209,\n",
       " 'tradit': 51193,\n",
       " 'agreement': 51135,\n",
       " 'phone': 51115,\n",
       " 'bomb': 51075,\n",
       " 'materi': 51071,\n",
       " 'enforc': 51046,\n",
       " 'jame': 51039,\n",
       " 'latest': 50994,\n",
       " 'shoot': 50993,\n",
       " 'hundr': 50771,\n",
       " 'goe': 50756,\n",
       " 'june': 50728,\n",
       " 'popular': 50682,\n",
       " 'island': 50672,\n",
       " 'sometim': 50629,\n",
       " 'juli': 50556,\n",
       " 'onlin': 50479,\n",
       " 'regard': 50456,\n",
       " 'cent': 50447,\n",
       " 'gop': 50283,\n",
       " 'movi': 50265,\n",
       " 'surpris': 50182,\n",
       " 'expert': 50118,\n",
       " 'firm': 50072,\n",
       " 'paper': 50040,\n",
       " 'seriou': 49985,\n",
       " 'ga': 49949,\n",
       " 'internet': 49805,\n",
       " 'british': 49796,\n",
       " 'compar': 49782,\n",
       " 'sent': 49711,\n",
       " 'approv': 49694,\n",
       " 'al': 49675,\n",
       " 'voic': 49547,\n",
       " 'bit': 49407,\n",
       " 'mention': 49378,\n",
       " 'road': 49372,\n",
       " 'destroy': 49370,\n",
       " 'heard': 49326,\n",
       " 'damag': 49299,\n",
       " 'employ': 49167,\n",
       " 'indic': 49047,\n",
       " 'declin': 48970,\n",
       " 'doctor': 48942,\n",
       " 'reserv': 48893,\n",
       " 'attent': 48873,\n",
       " 'suffer': 48843,\n",
       " 'declar': 48798,\n",
       " 'centuri': 48760,\n",
       " 'particip': 48643,\n",
       " 'met': 48606,\n",
       " 'advanc': 48601,\n",
       " 'contain': 48567,\n",
       " 'opinion': 48567,\n",
       " 'lawyer': 48518,\n",
       " 'lack': 48491,\n",
       " 'extrem': 48356,\n",
       " 'conduct': 48231,\n",
       " 'cancer': 48220,\n",
       " 'diseas': 48150,\n",
       " 'staff': 48095,\n",
       " 'ignor': 47987,\n",
       " 'primari': 47975,\n",
       " 'impact': 47915,\n",
       " 'pick': 47866,\n",
       " 'determin': 47854,\n",
       " 'ban': 47794,\n",
       " 'foundat': 47740,\n",
       " 'usual': 47625,\n",
       " 'strike': 47588,\n",
       " 'host': 47428,\n",
       " 'model': 47396,\n",
       " 'estim': 47321,\n",
       " 'spent': 47314,\n",
       " 'suppli': 47295,\n",
       " 'brought': 47054,\n",
       " 'lo': 47014,\n",
       " 'paid': 47007,\n",
       " 'signific': 46948,\n",
       " 'forward': 46874,\n",
       " 'knew': 46811,\n",
       " 'editor': 46784,\n",
       " 'confirm': 46556,\n",
       " 'novemb': 46502,\n",
       " 'victori': 46399,\n",
       " 'enter': 46390,\n",
       " 'amend': 46322,\n",
       " 'green': 46318,\n",
       " 'appar': 46318,\n",
       " 'object': 46203,\n",
       " 'earn': 46085,\n",
       " 'pressur': 46082,\n",
       " 'beyond': 46011,\n",
       " 'syrian': 45968,\n",
       " 'professor': 45935,\n",
       " 'huge': 45917,\n",
       " 'celebr': 45904,\n",
       " 'patient': 45837,\n",
       " 'basic': 45746,\n",
       " 'william': 45721,\n",
       " 'isra': 45707,\n",
       " 'violat': 45577,\n",
       " 'profit': 45532,\n",
       " 'alleg': 45527,\n",
       " 'custom': 45504,\n",
       " 'avoid': 45422,\n",
       " 'poor': 45378,\n",
       " 'relationship': 45261,\n",
       " 'surviv': 45250,\n",
       " 'oppos': 45246,\n",
       " 'option': 45244,\n",
       " 'agent': 45102,\n",
       " 'written': 45070,\n",
       " 'equal': 44886,\n",
       " 'contact': 44814,\n",
       " 'с': 44791,\n",
       " 'stage': 44777,\n",
       " 'king': 44754,\n",
       " 'owner': 44510,\n",
       " 'fox': 44492,\n",
       " 'commiss': 44405,\n",
       " 'brother': 44386,\n",
       " 'dead': 44370,\n",
       " 'resourc': 44290,\n",
       " 'financ': 44265,\n",
       " 'chines': 44126,\n",
       " 'abort': 44079,\n",
       " 'deni': 44003,\n",
       " 'encourag': 43996,\n",
       " 'modern': 43967,\n",
       " 'televis': 43889,\n",
       " 'sit': 43870,\n",
       " 'replac': 43851,\n",
       " 'minor': 43803,\n",
       " 'favor': 43738,\n",
       " 'arriv': 43692,\n",
       " 'certainli': 43683,\n",
       " 'titl': 43578,\n",
       " 'yesterday': 43473,\n",
       " 'edit': 43470,\n",
       " 'abus': 43446,\n",
       " 'pretti': 43396,\n",
       " 'marriag': 43327,\n",
       " 'purpos': 43304,\n",
       " 'politician': 43304,\n",
       " 'abil': 43292,\n",
       " 'affect': 43269,\n",
       " 'engag': 43226,\n",
       " 'april': 43219,\n",
       " 'previou': 43093,\n",
       " 'ca': 43084,\n",
       " 'safe': 43069,\n",
       " 'identifi': 43065,\n",
       " 'locat': 42956,\n",
       " 'labor': 42931,\n",
       " 'request': 42916,\n",
       " 'deliv': 42910,\n",
       " 'strategi': 42843,\n",
       " 'conflict': 42796,\n",
       " 'score': 42780,\n",
       " 'realiz': 42777,\n",
       " 'prove': 42776,\n",
       " 'histor': 42686,\n",
       " 'contract': 42683,\n",
       " 'difficult': 42645,\n",
       " 'except': 42609,\n",
       " 'attend': 42323,\n",
       " 'safeti': 42257,\n",
       " 'brown': 42245,\n",
       " 'boy': 42186,\n",
       " 'block': 42147,\n",
       " 'largest': 42120,\n",
       " 'physic': 42077,\n",
       " 'influenc': 41924,\n",
       " 'career': 41876,\n",
       " 'seat': 41850,\n",
       " 'command': 41843,\n",
       " 'battl': 41796,\n",
       " 'demonstr': 41754,\n",
       " 'particularli': 41597,\n",
       " 'treat': 41545,\n",
       " 'anim': 41456,\n",
       " 'worth': 41433,\n",
       " 'launch': 41399,\n",
       " 'analysi': 41393,\n",
       " 'observ': 41386,\n",
       " 'suprem': 41317,\n",
       " ...}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10000 most frequent words\n",
    "frequent_words_10k = dict(list(sorted_vocab.items()))\n",
    "frequent_words_10k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of URLS: 322213\n",
      "Amount of Dates: 270401\n",
      "Amount of Numbers: 7547782\n",
      "Amount of Emails: 154408\n"
     ]
    }
   ],
   "source": [
    "print('Amount of URLS:', sorted_vocab['url'])\n",
    "print('Amount of Dates:', sorted_vocab['date'])\n",
    "print('Amount of Numbers:', sorted_vocab['num'])\n",
    "print('Amount of Emails:', sorted_vocab['email'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(list(range(10000)), list(sorted_vocab.values())[:10000])\n",
    "plt.title('Most frequent words')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph of most frequent words follow Zipf's law (which is a powerlaw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: split data\n",
    "We use the sklearn train_test_split function to split the data into the different sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 536954\n",
      "Validation set size: 67120\n",
      "Test set size: 67119\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "new_sample = new_sample[2:]\n",
    "\n",
    "X = new_sample.drop(columns=[\"content\"]).values  # Feature columns\n",
    "y = new_sample[\"type\"].values  # Target column\n",
    "\n",
    "# 80% training and 20% rest for validation and test\n",
    "X_train, X_vt, y_train, y_vt = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)\n",
    "\n",
    "# Split 20% into 10% validation and 10% test\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_vt, y_vt, test_size=0.5, random_state=0, stratify=y_vt)\n",
    "\n",
    "# Print number of samples in each dataset\n",
    "print(f\"Training set size: {X_train.shape[0]}\")\n",
    "print(f\"Validation set size: {X_val.shape[0]}\")\n",
    "print(f\"Test set size: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Simple Logitstic Regression\n",
    "\n",
    "* Binary classification: `reliabe` or `fake`\n",
    "\n",
    "### Task 0: Label grouping\n",
    "0: `fake`\n",
    "1: `reliable`\n",
    "\n",
    "From part 1 task 1 we've defined a function `is_credible()` and classified the types into reliable or fake by using binary classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Logistic regression classifier\n",
    "* Fixed vocab of 10000 most frequent words.\n",
    "* F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy on validation set:  0.8435465367481637\n",
      "Logistic Regression F1-score on validation set:  0.8631024547955206\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Drop missing content rows\n",
    "new_sample = new_sample.dropna(subset=[\"content\"])\n",
    "\n",
    "# Convert to string just to be safe\n",
    "texts = new_sample[\"content\"].astype(str)\n",
    "labels = new_sample[\"type\"].values\n",
    "\n",
    "# Vectorize using TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=10000,        # Use the top 10,000 most frequent words\n",
    "    lowercase=True,\n",
    "    stop_words='english',      # Optional: remove stopwords\n",
    ")\n",
    "X = vectorizer.fit_transform(texts)  # Returns a sparse matrix\n",
    "y = labels\n",
    "\n",
    "# Train/Test Split (80% Train, 10% Validation, 10% Test)\n",
    "X_train, X_vt, y_train, y_vt = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_vt, y_vt, test_size=0.5, random_state=0, stratify=y_vt)\n",
    "\n",
    "# Train Logistic Regression Model\n",
    "modelLog = LogisticRegression(max_iter=500, solver=\"lbfgs\", C=1.0)\n",
    "modelLog.fit(X_train, y_train)\n",
    "\n",
    "# Make Predictions\n",
    "y_pred = modelLog.predict(X_val)\n",
    "\n",
    "# Evaluate Model Performance\n",
    "accuracy_val = accuracy_score(y_val, y_pred)\n",
    "f1_val = f1_score(y_val, y_pred)\n",
    "\n",
    "# Print Results\n",
    "print(\"Logistic Regression Accuracy on validation set: \", accuracy_val)\n",
    "print(\"Logistic Regression F1-score on validation set: \", f1_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Apply preproccessing pipeline to scraped reliable data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_news = pd.read_csv(\"src/bbc_news.csv\")\n",
    "target_news[\"content\"] = target_news[\"content\"].apply(full_clean)\n",
    "target_news.to_csv(\"src/clean_bbc_news.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             content  prediction\n",
      "0  denmark postal servic postnord end letter deli...           1\n",
      "1  eu leader gather brussel thursday special coun...           0\n",
      "2  summit mark major signific manifest reset rela...           0\n",
      "3  cleaner scrub debat chamber clean mp arriv wed...           1\n",
      "4  british man captur fight ukrain arm forc jail ...           0\n",
      "5  whether ukrain presid volodymyr zelenski decis...           1\n",
      "6  pope franci woke num num local time num num gm...           0\n",
      "7  ten thousand romanian march bucharest victori ...           0\n",
      "8  certainli one way focus mind wallet donald tru...           0\n",
      "9  friedrich merz expect becom germani next chanc...           0\n"
     ]
    }
   ],
   "source": [
    "bbc_news = pd.read_csv(\"src/clean_bbc_news.csv\")\n",
    "\n",
    "# Convert to string just to be safe\n",
    "bbc_texts = bbc_news[\"content\"].astype(str)\n",
    "\n",
    "X_bbc = vectorizer.transform(bbc_texts)  # Returns a sparse matrix\n",
    "\n",
    "# Predict Fake or Reliable\n",
    "bbc_pred = modelLog.predict(X_bbc)\n",
    "\n",
    "# Store Results\n",
    "bbc_news[\"prediction\"] = bbc_pred  # Append predictions to the dataset\n",
    "\n",
    "# Save Predictions to a CSV File\n",
    "bbc_news.to_csv(\"src/classified_bbc_news.csv\", index=False)\n",
    "\n",
    "# Display Results\n",
    "print(bbc_news[[\"content\", \"prediction\"]].head(10))  # Show first 10 predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'classified articles fake: 271, and reliable: 401'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classified_news = pd.read_csv(\"src/classified_bbc_news.csv\")\n",
    "classified_news[\"prediction\"]\n",
    "\n",
    "def counting(classified):\n",
    "    reliable = 0\n",
    "    fake = 0\n",
    "\n",
    "    for classification in classified:\n",
    "        if classification == 0 :\n",
    "            fake += 1\n",
    "        elif classification == 1:\n",
    "            reliable += 1\n",
    "\n",
    "    return (f\"classified articles fake: {fake}, and reliable: {reliable}\")\n",
    "\n",
    "counting(list(classified_news['prediction']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Advanced model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "#ensure reproducibility\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Load data frequent words\n",
    "freq_words = pd.read_csv(\"src/frequent_words_10k.csv\")\n",
    "frequent_words = set(freq_words['word'].astype(str).str.strip())\n",
    "\n",
    "# load articles dataset\n",
    "articles = pd.read_csv(\"src/clean_995000_news.csv\") #locally downloaded \"/clean_995000_news.csv\"\n",
    "articles.columns = articles.columns.str.strip()\n",
    "articles['content'] = articles['content'].astype(str)\n",
    "\n",
    "\n",
    "# Filter only top 10000 words\n",
    "def filter_article(text, allowed_words):\n",
    "    tokens = text.split()\n",
    "    return ' '.join([word for word in tokens if word in allowed_words])\n",
    "\n",
    "articles['filtered_content'] = articles['content'].apply(lambda x: filter_article(x, frequent_words))\n",
    "# drop empty \n",
    "articles = articles[articles['filtered_content'].str.strip().astype(bool)].reset_index(drop=True)\n",
    "\n",
    "\n",
    "# TF-IDF vectorization  sparse, every article is a vector of the TF-IDF numerical values only non-zero\n",
    "vectorizer = TfidfVectorizer(max_features=10000)\n",
    "X_sparse = vectorizer.fit_transform(articles['filtered_content'])\n",
    "# label binary values\n",
    "y = articles['type'].astype(int).values\n",
    "\n",
    "\n",
    "# Train/Val/Test split\n",
    "X_train, X_vt, y_train, y_vt = train_test_split(X_sparse, y, test_size=0.2, random_state=0)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_vt, y_vt, test_size=0.5, random_state=0)\n",
    "\n",
    "\n",
    "# Define neural network (inherited form the torch.nn.module class)\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        # Setup in layers\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 512)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(512, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        # How the data flows\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(self.relu(self.fc1(x)))\n",
    "        x = self.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "# Model setup\n",
    "input_size = X_sparse.shape[1]\n",
    "model = NeuralNetwork(input_size)\n",
    "# Error function - binary cross entropy \n",
    "loss_fn = nn.BCELoss()\n",
    "# Adam algorithm for stochastic gradient descent, lr = learning rate, weight_decay = penalty for large weights (prevent overfitting)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005, weight_decay=1e-5)\n",
    "\n",
    "\n",
    "# Model training loop, manual batching, only converting to dense (tensor) when needed\n",
    "# Batch = articles at a time\n",
    "batch_size = 128\n",
    "# Epochs = how many times the model will go though all training data (too many times = over fitting)\n",
    "epochs = 6\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    # Get training data in random order across epochs\n",
    "    permutation = np.random.permutation(X_train.shape[0])\n",
    "\n",
    "    for i in range(0, X_train.shape[0], batch_size):\n",
    "        batch_indices = permutation[i:i + batch_size]\n",
    "        X_batch_sparse = X_train[batch_indices]\n",
    "        y_batch = y_train[batch_indices]\n",
    "\n",
    "        # Sparse to dense (just for batch)\n",
    "        X_batch_dense = torch.tensor(X_batch_sparse.toarray(), dtype=torch.float32)\n",
    "        y_batch_tensor = torch.tensor(y_batch, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(X_batch_dense)\n",
    "        loss = loss_fn(outputs, y_batch_tensor)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * X_batch_dense.size(0)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        X_val_tensor = torch.tensor(X_val.toarray(), dtype=torch.float32)\n",
    "        y_val_tensor = torch.tensor(y_val, dtype=torch.float32).view(-1, 1)\n",
    "        val_outputs = model(X_val_tensor)\n",
    "        val_loss = loss_fn(val_outputs, y_val_tensor).item()\n",
    "\n",
    "    avg_train_loss = train_loss / X_train.shape[0]\n",
    "    print(f\"Epoch {epoch + 1}/{epochs} | Train Loss: {avg_train_loss:.4f} | Val Loss: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Evaluation\n",
    "### Task 1: \n",
    "#### Logistic Regression model on test-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy on test set:  0.8450983313468414\n",
      "Logistic Regression F1-score on test set:  0.8644052323382501\n"
     ]
    }
   ],
   "source": [
    "# Make Predictions\n",
    "y_pred = modelLog.predict(X_test)\n",
    "\n",
    "# Evaluate Model Performance\n",
    "accuracy_test = accuracy_score(y_test, y_pred)\n",
    "f1_test = f1_score(y_test, y_pred)\n",
    "\n",
    "# Print Results\n",
    "print(\"Logistic Regression Accuracy on test set: \", accuracy_test)\n",
    "print(\"Logistic Regression F1-score on test set: \", f1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Network model on test-data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate / test \n",
    "with torch.no_grad():\n",
    "    X_test_tensor = torch.tensor(X_test.toarray(), dtype=torch.float32)\n",
    "    y_test_tensor = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)\n",
    "    \n",
    "    y_pred_probs = model(X_test_tensor)\n",
    "    y_pred_labels = (y_pred_probs >= 0.5).float()\n",
    "\n",
    "    accuracy = accuracy_score(y_test_tensor.numpy(), y_pred_labels.numpy())\n",
    "    f1 = f1_score(y_test_tensor.numpy(), y_pred_labels.numpy())\n",
    "\n",
    "    print(f'Test Accuracy: {accuracy:.4f} | f1 score: {f1:.4f}')\n",
    "    print(classification_report(y_test_tensor.numpy(), y_pred_labels.numpy()))\n",
    "    print(confusion_matrix(y_test_tensor.numpy(), y_pred_labels.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2:\n",
    "#### Logistic Regression model on LIAR dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "liar_test = pd.read_csv('liar_dataset/test.tsv', sep='\\t', header=None, \n",
    "                        usecols=[1,2]).rename(columns={1:'type', 2:'content'})\n",
    "liar_test\n",
    "\n",
    "def is_credible_liar(article_type):\n",
    "    if article_type in ['false', 'pants-fire', 'barely-true']:\n",
    "        return 0\n",
    "    elif article_type in ['half-true', 'mostly-true', 'true']:\n",
    "        return 1\n",
    "    \n",
    "liar_test['content'] = liar_test['content'].apply(full_clean)\n",
    "liar_test['type'] = liar_test['type'].apply(is_credible_liar)\n",
    "\n",
    "liar_test.to_csv('src/clean_liar_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             content  prediction\n",
      "0                  build wall border take liter year           1\n",
      "1            wisconsin pace doubl number layoff year           0\n",
      "2                 say john mccain done noth help vet           1\n",
      "3  suzann bonamici support plan cut choic medicar...           1\n",
      "4  ask report whether he center crimin scheme vio...           1\n",
      "5  past five year feder govern paid num million r...           0\n",
      "6  say tennesse law requir school receiv half pro...           1\n",
      "7  say vice presid joe biden admit american peopl...           0\n",
      "8            donald trump marriag equal want go back           1\n",
      "9  know half hillari clinton meet secretari state...           0\n",
      "Logistic Regression Accuracy on liar set:  0.5477505919494869\n",
      "Logistic Regression F1-score on liar set:  0.6276803118908382\n"
     ]
    }
   ],
   "source": [
    "liar_test = pd.read_csv('src/clean_liar_test.csv')\n",
    "\n",
    "# Convert to string just to be safe\n",
    "texts = liar_test[\"content\"].astype(str)\n",
    "labels = liar_test[\"type\"].values\n",
    "\n",
    "# Use the original vectorizer (already fitted on training data)\n",
    "X_liar = vectorizer.transform(texts)\n",
    "y_liar = labels\n",
    "\n",
    "# Predict\n",
    "liar_pred = modelLog.predict(X_liar)\n",
    "\n",
    "# Store and Display Results\n",
    "liar_test[\"prediction\"] = liar_pred\n",
    "print(liar_test[[\"content\", \"prediction\"]].head(10))\n",
    "\n",
    "# Evaluate\n",
    "accuracy_liar = accuracy_score(y_liar, liar_pred)\n",
    "f1_liar = f1_score(y_liar, liar_pred)\n",
    "\n",
    "print(\"Logistic Regression Accuracy on liar set: \", accuracy_liar)\n",
    "print(\"Logistic Regression F1-score on liar set: \", f1_liar)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Network model on LIAR dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Liars dataset test using the model form before\n",
    "liar_articles = pd.read_csv(\"src/clean_liar_test.csv\")\n",
    "liar_articles.columns = liar_articles.columns.str.strip()\n",
    "liar_articles['content'] = liar_articles['content'].astype(str)\n",
    "\n",
    "#filter for 10000 most freq words\n",
    "liar_articles['filtered_liar'] = liar_articles['content'].apply(lambda x: filter_article(x, frequent_words))\n",
    "# drop empty \n",
    "liar_articles = liar_articles[liar_articles['filtered_liar'].str.strip().astype(bool)].reset_index(drop=True)\n",
    "\n",
    "\n",
    "# TF-IDF vectorization  sparse, every article is a vector of the TF-IDF numerical values only non-zero\n",
    "X_sparse_liar = vectorizer.transform(liar_articles['filtered_liar'])\n",
    "# label binary values\n",
    "y_liar = liar_articles['type'].astype(int).values\n",
    "\n",
    "with torch.no_grad():\n",
    "    X_liar_tensor = torch.tensor(X_sparse_liar.toarray(), dtype=torch.float32)\n",
    "    y_liar_tensor = torch.tensor(y_liar, dtype=torch.float32).view(-1, 1)\n",
    "    \n",
    "    y_pred_probs_liar = model(X_liar_tensor)\n",
    "    y_pred_labels_liar = (y_pred_probs_liar >= 0.5).float()\n",
    "\n",
    "    accuracy_liar = accuracy_score(y_liar_tensor.numpy(), y_pred_labels_liar.numpy())\n",
    "    f1_liar = f1_score(y_liar_tensor.numpy(), y_pred_labels_liar.numpy())\n",
    "    \n",
    "    print(f'Test Accuracy: {accuracy_liar:.4f} | f1 score: {f1_liar:.4f}')\n",
    "    print(classification_report(y_liar_tensor.numpy(), y_pred_labels_liar.numpy()))\n",
    "    print(confusion_matrix(y_liar_tensor.numpy(), y_pred_labels_liar.numpy()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GDSE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
